{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34c84155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERCEPTO: Ordenada en el origen del modelo de regresión logística [-3.14]\n",
      "PENDIENTE: Estimadores de las variables independientes del modelo de regresión logística [[1.15]]\n",
      "Probabilidades estimadas por el modelo de regresión logística: \n",
      " [0.195 0.301 0.576 0.433 0.093 0.931]\n",
      "Punto de corte 0.5 [0 0 1 0 0 1]\n",
      "Punto de corte 0.4 [0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# ******************************************************************************************************************************\n",
    "# *** ¿ Qué es la REGRESIÓN LOGÍSTICA ?:\n",
    "# *** Es un MODELO SUPERVISADO que devuelve propabilidades de éxito ( entre 0 y 1 ) haciendo uso de la transformación logarítmica.\n",
    "# *** La regresión logística es un modelo estadístico que utiliza la función logística, o FUNCION LOGIT, en matemáticas como la\n",
    "# *** ecuación entre 'X' e 'Y'. La función logit mapea 'Y' como una función sigmoidea de 'X' ( Ver imagen de la función )\n",
    "# *** Mas informacion en el enlace:\n",
    "# *** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# ******************************************************************************************************************************\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# DataSet PARA PROBAR LA REGRESION LOGÍSTICA ( Modelo Supervisado ):\n",
    "# HORAS DE ESTUDIO: Horas de estudio diarias de alumnos de matemáticas.\n",
    "# APROBADO: 'Target' dicotómico sobre si aprobaron o suspendieron la asignatura.\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Horas_estudio\": [0.5, 0.75, 1, 1.25, 1.5, 1.75, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25, 3.5, 4, 4.25, 4.5, 4.75, 5, 5.5],\n",
    "    \"Aprobado\": [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n",
    "})\n",
    "\n",
    "#df\n",
    "\n",
    "# Vamos a ENTRENAR NUESTRO MODELO con los DATOS DE ENTRADA ( en este caso serían \"datos de ENTRENAMIENTO\")\n",
    "x = np.array(df[\"Horas_estudio\"]).reshape(-1, 1)\n",
    "y = np.array(df[\"Aprobado\"])\n",
    "resultado_reg_log = LogisticRegression().fit(x,y)\n",
    "\n",
    "# La formula de una regresion lineal es: Y = INTERCEPTO + ( PENDIENTE * X )\n",
    "\n",
    "# Ordenada en el origen:\n",
    "print(f\"INTERCEPTO: Ordenada en el origen del modelo de regresión logística {resultado_reg_log.intercept_.round(2)}\")\n",
    "# Estimación del coeficiente:\n",
    "print(f\"PENDIENTE: Estimadores de las variables independientes del modelo de regresión logística {resultado_reg_log.coef_.round(2)}\")\n",
    "\n",
    "# Nuestra REGRESION LOGISTICA QUEDA CALCULADA COMO: logit(P) = -3.14 + 1.15 * X ( Horas de Estudio )\n",
    "# Ahora la aplicamos a un nuevo DataSet ( desconocido por el modelo ) que serían los \"datos de TEST\"\n",
    "\n",
    "nuevo_vector_horas = np.array([1.5, 2, 3, 2.5, 0.75, 5]).reshape(-1,1)\n",
    "\n",
    "probabilidades_prediccion = resultado_reg_log.predict_proba(nuevo_vector_horas)\n",
    "print(\"Probabilidades estimadas por el modelo de regresión logística: \\n\", probabilidades_prediccion[:,1].round(3))\n",
    "\n",
    "# *** Hasta este punto hemos obtenido PROBABILIDADES ( % ), pero queremos conseguir valores concreto ( 1 o 0 - Aprueba o No ).\n",
    "# *** Para ello se establecen los \"PUNTOS DE CORTE\" ( que por defecto es 0,5 ). En este caso es perfecto porque lo que pase de\n",
    "# *** ese 0'5 ( 1+0 / 2 ) sera APROBADO ( y por debajo sera SUSPENSO ) --> Aprobarían 2 alumnos de los 6\n",
    "\n",
    "prediccion = resultado_reg_log.predict(nuevo_vector_horas)\n",
    "print(\"Punto de corte 0.5\",prediccion)\n",
    "\n",
    "# *** NOTA: EL PUNTO DE CORTE se puede modificar a gusto ( y criterio ) del analista:\n",
    "threshold = 0.4 # Se establece en 0'4\n",
    "pred = (resultado_reg_log.predict_proba(nuevo_vector_horas) > threshold).astype('int')\n",
    "print(\"Punto de corte 0.4\",pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8142bb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERCEPTO: [-2.91]\n",
      "PENDIENTE: [[1.08]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *********************************************************************************************************\n",
    "# **** 1.- TECNICA TRAIN-TEST VALIDATION\n",
    "# *** NUNCA se hace el entrenamiento del modelo con el 100% del DataSet --> Provocaria SOBREAJUSTE\n",
    "# *** Por ello, se divide en dos partes \"Train\" ( 75-80% ) y \"Test\" ( 25-20% )\n",
    "# *** ES UNA DE LAS TECNICAS MAS UTILIZADAS\n",
    "# *********************************************************************************************************\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#train_test_split aleatoriamente divide la base de datos en train y validación antendiendo a un porcentaje.\n",
    "\n",
    "x = np.array(df[\"Horas_estudio\"]).reshape(-1, 1)\n",
    "y = np.array(df[\"Aprobado\"])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.20)\n",
    "#print(\"x_train\", x_train)\n",
    "#print(\"x_test\", x_test)\n",
    "#print(\"y_train\", y_train)\n",
    "#print(\"y_test\", y_test)\n",
    "#x_train: suconjunto de variables independientes asociado a train\n",
    "#y_train: subconjuto de variable target asociado a train\n",
    "#x_test: suconjunto de variables independientes asociado a test\n",
    "#y_test: subconjuto de variable target asociado a test\n",
    "\n",
    "modelo_ajusta_train = LogisticRegression().fit(x_train, y_train)\n",
    "#Ordenada en el origen:\n",
    "print(f\"INTERCEPTO: {modelo_ajusta_train.intercept_.round(2)}\")\n",
    "#Estimación del coeficiente:\n",
    "print(f\"PENDIENTE: {modelo_ajusta_train.coef_.round(2)}\")\n",
    "\n",
    "# Nuestra REGRESION LOGISTICA QUEDA CALCULADA COMO: logit(P) = -2.55 + 0.99 * X ( Horas de Estudio )\n",
    "\n",
    "# SCORE aplica el modelo ajustado en TRAIN en la parte de TEST y devuelve el coeficiente de determinación del modelo de regresión. \n",
    "# Esto es, la varianza explicada por lo predicho frente a la variable real, a mayor valor, mejor.\n",
    "result = modelo_ajusta_train.score(x_test, y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3490fcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *********************************************************************************************************\n",
    "# *** 2.- TECNICA K-FOLDS CROSS VALIDATION\n",
    "# *** Es igual que la anterior pero divide el DataSet en K-Partes ( donde una de ellas testea el modelo cada vez )\n",
    "# *** Se asegura de utilizar TODOS los registros para entrenar el modelo ( no deja un % aparate --> Evita sesgo )\n",
    "# *** Es LA MAS UTILIZADA DE TODAS !!! ( es la más robusta de todas, pero también la más lenta )\n",
    "# *********************************************************************************************************\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "kfold = KFold(n_splits=10)\n",
    "model = LogisticRegression()\n",
    "\n",
    "result = cross_val_score(model, x, y, cv=kfold)\n",
    "result\n",
    "result.mean()\n",
    "\n",
    "# Devuelve un array por cada iteracion, dando la puntuacion conseguida. Al final se calcula una media de todos.\n",
    "# N os quedariamos con el que mejor puntuacion tenga ( con los que tengan 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22501644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *********************************************************************************************************\n",
    "# *** 3.- TECNICA LOO CROSS VALIDATION\n",
    "# *** Divide el DataSet en K-Partes ( donde K es el numero de registros - Ver imagen )\n",
    "# *** Es iterativo y emplea TODAS las observaciones MENOS UNA como entrenamiento y \"esa una\" como validacion\n",
    "# *** NADA RECOMENDABLE !!.. Porque prueba el modelo sobre una unica observacion\n",
    "# *********************************************************************************************************\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "model = LogisticRegression()\n",
    "result_loo = cross_val_score(model, x, y, cv=loo)\n",
    "result_loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9ca65d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 0.5 , 0.75, 1.  , 1.  , 0.75, 0.5 , 0.75, 0.5 , 0.75])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ********************************************************************************************************************\n",
    "# *** 4.- TECNICA SHUFFLE SPLIT CROSS VALIDATION\n",
    "# *** La division entre \"train\" y \"test\" es totalmente aleatoria por lo que las particiones pueden coincidir entre si.\n",
    "# *** Tampoco es recomendable\n",
    "# *** Mas informacion en el enlace:\n",
    "# *** https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "# ********************************************************************************************************************\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "\n",
    "kfold = ShuffleSplit(n_splits=10, test_size = 0.20, random_state=2)\n",
    "model = LogisticRegression()\n",
    "\n",
    "result = cross_val_score(model, x, y, cv=kfold)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c4f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
